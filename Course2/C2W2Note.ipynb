{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Training NN with a large data set is slow. So to find an optimization algorithm that runs faster is a good idea.\n",
    "- Suppose we have $m=50,000,000$, to train this data it will take a huge processing time for one step (because $50,000,000$ wouldn't fit in the memory at one we need other processing to make such a thing)\n",
    "- It turns out you can make a faster algorithm to make gradient descent process some of your items even before you finish the $50,000,000$\n",
    "- We similarly split $X$ \\& $Y$, so the definition of mini-batches: $t: X\\{t\\}, Y\\{t\\}$\n",
    "<img src=\"screenshot/5.PNG\" style=\"width:600px;height:350px;\">\n",
    "- In **batch gradient descent**, we run the gradient descent on the whole data set.\n",
    "- In **mini-batch gradient descent**, we run the gradient descent on the mini data sets.\n",
    "- Mini-batch algorithm pseudo-code:\n",
    "<img src=\"screenshot/6.PNG\" style=\"width:600px;height:350px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding mini-batch gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the mini-batch algorithm, the cost wouldn't go down with each step as it does in the batch algorithm. It could contain some ups and downs, but it has to go down generally (which is unlike the batch gradient where cost function decreases on each iteration)\n",
    "<img src=\"screenshot/7.PNG\" style=\"width:600px;height:350px;\">\n",
    "- Mini-batch size:\n",
    "\n",
    "(1) $m$: batch gradient descent: too long per iteration\n",
    "\n",
    "(2) $1$: Stochastic gradient descent (SGD): \n",
    "    - too noisy regarding cost minimization (can be reduced by using a smaller learning rate);\n",
    "    - won't ever converge (reach the minimum cost); \n",
    "    - lose speedup from vectorization\n",
    "\n",
    "(3) Between $1$ and $m$: mini-batch gradient descent: \n",
    "    - faster learning (have the vectorization advantage; make progress without waiting to process the entire training set); \n",
    "    - doesn't always exactly converge (oscillates in a very small region, can reduce the learning rate)\n",
    "\n",
    "- Guidelines for choosing mini-batch size:\n",
    "<img src=\"screenshot/8.PNG\" style=\"width:600px;height:350px;\">\n",
    "\n",
    "(1) If small training set ($<2000$ examples)--use batch gradient descent\n",
    "\n",
    "(2) It has to be a power of $2$ (because of the way of computer memory is laid out and accessed, sometimes your code runs faster if your mini-batch size is a power of $2$): $64, 128, 256, 512, 1024, \\dots$\n",
    "\n",
    "(3) Make sure that mini-batch fits CPU/GPU memory\n",
    "\n",
    "**Mini-batch size is a hyperparameter**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponentially weighted averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are optimization algorithms that are better than **gradient descent**, but you should first learn about exponentially weighted averages.\n",
    "\n",
    "- General equation: $V(t)=\\beta*V(t-1)+(1-\\beta)*\\theta(t)$\n",
    "- If we plot this it will represent averages over $\\approx(1/(1-\\beta))$ entries:\n",
    "    - $\\beta=0.9$ will average last $10$ entries\n",
    "    - $\\beta=0.98$ will average last $50$ entries\n",
    "    - $\\beta=0.5$ will average last $2$ entries\n",
    "**Best $\\beta$ average for our case is between $0.9$ and $0.98$**\n",
    "- Intuition: The reason why exponentially weighted averages are useful for further optimizing gradient descent algorithm is that it can give different weights to recent data points $\\theta$ based on the value of $\\beta$. If $\\beta$ is high (around $0.9$), it smoothens out the average of skewed data points (oscillations). So this reduces oscillations in gradient descent and hence makes a faster and smoother path towards minima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponentially weighted averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Intuitions:\n",
    "<img src=\"screenshot/9.PNG\" style=\"width:600px;height:350px;\">\n",
    "- We can implement this algorithm with more accurate results using a moving window. But the code is more efficient and faster using the exponentially weighted averages algorithm.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&Repeat:\\\\\n",
    "&\\quad get \\theta(t)\\\\\n",
    "&\\quad v=\\beta*v + (1-\\beta)*\\theta(t) \n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias correction in exponentially weighted averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The bias correction helps make the exponentially weighted averages more accurate\n",
    "- Because $V(0)=0$, the bias of the weighted averages is shifted and the accuracy suffers at the start\n",
    "To solve the bias issue, we have to use the following equation: \n",
    "$$\n",
    "V(t)=\\beta*V(t-1)+(1-\\beta)*\\theta(t)/(1-\\beta^{t})\n",
    "$$\n",
    "- As $t$ becomes larger, $1-\\beta^{t}$ becomes close to $1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent with momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The momentum algorithm almost always works faster than standard gradient descent\n",
    "- The simple idea is to calculate the exponentially weighted averages for your gradients and then update your weights with the new values\n",
    "- Algorithm:\n",
    "<img src=\"screenshot/10.PNG\" style=\"width:600px;height:350px;\">\n",
    "- Momentum helps the cost function to go to the minimum point in a more fast and consistent way\n",
    "- $\\beta$ is another hyperparameter. $\\beta=0.9$ is very common and works very well in most cases\n",
    "- In practice, people don't bother implementing bias correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSprop (Root mean square prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This algorithm speeds up the gradient descent\n",
    "- RMSprop will make the cost function move slower on the vertical direction and faster on the horizontal direction in the following example\n",
    "<img src=\"screenshot/11.PNG\" style=\"width:600px;height:350px;\">\n",
    "- Make sure that $S_{dw}$ is not zero by adding a small value $\\epsilon$ ($\\epsilon=10^{-8}$) to it\n",
    "- With RMSprop you can increase your learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam optimization algorithm (Adaptive Moment Estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adam optimization and RMSprop are among the optimization algorithm that worked very well with lots of NN architectures.\n",
    "- Adam optimization simply puts RMSprop and momentum together\n",
    "<img src=\"screenshot/12.PNG\" style=\"width:600px;height:350px;\">\n",
    "- Hyperparameters for Adam:\n",
    "    - Learning rate: needed to be tuned\n",
    "    - $\\beta_{1}$: parameter of the momentum--$0.9$ is recommended by default\n",
    "    - $\\beta_{2}$: parameter of the RMSprop--$0.999$ is recommended by default\n",
    "    - $\\epsilon$: $10^{-8}$ is recommended by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Slowly reduce the learning rate\n",
    "- As mentioned before the mini-batch gradient descent won't reach the optimum point (converge). But by making the learning rate decay with iterations, it will be much closer to it because the steps (and possible oscillations) near optimum are smaller.\n",
    "- One technique equation is \n",
    "$$\n",
    "learning\\_rate=(1/(1+decay\\_rate*epoch\\_num))*learning\\_rate0\n",
    "$$\n",
    "where epoch_num is over all data (not a single mini-batch)\n",
    "- Other learning rate decay methods (continuous)\n",
    "    - $learning\\_rate=(0.95^{epoch\\_num})*learning\\_rate0$\n",
    "    - $learning\\_rate=(k/\\sqrt{epoch\\_num})*learning\\_rate0$\n",
    "- Some people perform learning rate decay discretely--repeatedly decrease after some number of echos\n",
    "- Some people are making changes to the learning rate manually\n",
    "- The decay_rate is another hyperparameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem of local optima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The normal local optimum is not likely to appear in a deep neural network because data is usually high dimensional. For point to be a local optimum it has to be a local optimum for each of the highly unlikely dimensions\n",
    "- It's unlikely to get stuck in a bad local optimum in high dimensions. It is much more likely to get to the saddle point rather than to the local optimum, which is not a problem.\n",
    "- Plateaus can make the learning slow:\n",
    "    - Plateaus is a region where the derivative is close to zero for a long time\n",
    "    - This is where algorithms like momentum, RMSprop or Adam can help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
